{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8090d1db-844d-4df6-9706-c7228460bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df = pd.read_csv(\"/Users/berni/Desktop/trial1.csv\")\n",
    "\n",
    "# Display first 5 rows\n",
    "# print(df.head())\n",
    "\n",
    "# Access specific column\n",
    "# print(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ebe504d9-aad0-414f-8d7b-864c06594a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               Climate Data Online (CDO)\n",
      "1                      Search | Climate Data Online (CDO)\n",
      "2                          Maps & Data | NOAA Climate.gov\n",
      "3                      Climate - National Weather Service\n",
      "4                                               WorldClim\n",
      "                              ...                        \n",
      "2174    Adapting to the business future - Otago Daily ...\n",
      "2175    NC Businesses Call for Commitment to Carbon Re...\n",
      "2176    Aboitiz Foundation Champions Sustainability At...\n",
      "2181    The Second Trump Administration and Europe's G...\n",
      "2182    Op-Ed: Harrell's Growth Plan Shorts Housing an...\n",
      "Name: title, Length: 2017, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter out uncredible words\n",
    "\n",
    "# Define keywords to filter out\n",
    "keywords = ['blog',\n",
    "            'opinion',\n",
    "            'click',\n",
    "            'sponsored',\n",
    "            'advertisement',\n",
    "            'wordpress',\n",
    "           'wix',\n",
    "           'quora',\n",
    "           'reddit',\n",
    "           'weebly',\n",
    "           'blogspot',\n",
    "           'substack',\n",
    "           'linkedin',\n",
    "           'wikipedia',\n",
    "           'are you',\n",
    "           'job',\n",
    "           'career',\n",
    "           'shop',\n",
    "           'sign in',\n",
    "           '@',\n",
    "           'youtube',\n",
    "           'instagram']\n",
    "\n",
    "mask = ~df.apply(\n",
    "    lambda row: row.astype(str).str.contains(\n",
    "        '|'.join(keywords),  # Regex \"OR\" pattern\n",
    "        case=False)).any(axis=1)\n",
    "\n",
    "# Apply the mask\n",
    "df1 = df[mask]\n",
    "\n",
    "print(df1['title'])\n",
    "\n",
    "# Save the cleaned dataframe\n",
    "# df.to_csv('cleaned_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d9733207-4766-46a9-b199-1801e993beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      https://www.ncei.noaa.gov/cdo-web/\n",
      "1                https://www.ncdc.noaa.gov/cdo-web/search\n",
      "2                       https://www.climate.gov/maps-data\n",
      "3                     https://www.weather.gov/wrh/climate\n",
      "5           https://climateknowledgeportal.worldbank.org/\n",
      "                              ...                        \n",
      "2174    https://www.odt.co.nz/lifestyle/magazine/adapt...\n",
      "2175    https://www.nrdc.org/press-releases/businesses...\n",
      "2176    https://journal.com.ph/aboitiz-foundation-cham...\n",
      "2181    https://www.globsec.org/what-we-do/commentarie...\n",
      "2182    https://www.theurbanist.org/2025/03/29/harrell...\n",
      "Name: link, Length: 1993, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with links as titles\n",
    "\n",
    "df1 = df1[df1['title'].str.split().str.len() != 1]\n",
    "\n",
    "print(df1['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0f9287ab-a9d6-488a-af24-7bdc7f90e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        query  rank  \\\n",
      "0            climate database     1   \n",
      "1            climate database     2   \n",
      "2            climate database     3   \n",
      "3            climate database     4   \n",
      "5            climate database     6   \n",
      "...                       ...   ...   \n",
      "2174  climate adaptation plan    90   \n",
      "2175  climate adaptation plan    92   \n",
      "2176  climate adaptation plan    93   \n",
      "2181  climate adaptation plan    72   \n",
      "2182  climate adaptation plan    80   \n",
      "\n",
      "                                                  title  \\\n",
      "0                             Climate Data Online (CDO)   \n",
      "1                    Search | Climate Data Online (CDO)   \n",
      "2                        Maps & Data | NOAA Climate.gov   \n",
      "3                    Climate - National Weather Service   \n",
      "5                 Climate Change Knowledge Portal: Home   \n",
      "...                                                 ...   \n",
      "2174  Adapting to the business future - Otago Daily ...   \n",
      "2175  NC Businesses Call for Commitment to Carbon Re...   \n",
      "2176  Aboitiz Foundation Champions Sustainability At...   \n",
      "2181  The Second Trump Administration and Europe's G...   \n",
      "2182  Op-Ed: Harrell's Growth Plan Shorts Housing an...   \n",
      "\n",
      "                                                   link  \\\n",
      "0                    https://www.ncei.noaa.gov/cdo-web/   \n",
      "1              https://www.ncdc.noaa.gov/cdo-web/search   \n",
      "2                     https://www.climate.gov/maps-data   \n",
      "3                   https://www.weather.gov/wrh/climate   \n",
      "5         https://climateknowledgeportal.worldbank.org/   \n",
      "...                                                 ...   \n",
      "2174  https://www.odt.co.nz/lifestyle/magazine/adapt...   \n",
      "2175  https://www.nrdc.org/press-releases/businesses...   \n",
      "2176  https://journal.com.ph/aboitiz-foundation-cham...   \n",
      "2181  https://www.globsec.org/what-we-do/commentarie...   \n",
      "2182  https://www.theurbanist.org/2025/03/29/harrell...   \n",
      "\n",
      "                                                snippet  page title_cities  \\\n",
      "0     Climate Data Online (CDO) provides free access...     1           []   \n",
      "1     Start searching here to find past weather and ...     1           []   \n",
      "2     This site provides data tables for comparing r...     1           []   \n",
      "3     For the latest climate forecasts see the Clima...     1           []   \n",
      "5     The Portal provides an online tool for access ...     1           []   \n",
      "...                                                 ...   ...          ...   \n",
      "2174  6 days ago · Climate change adaptation for bus...     9           []   \n",
      "2175  3 days ago · Climate Adaptation · Fossil Fuels...     9           []   \n",
      "2176  17 hours ago · Themed “Advancing Private Secto...     9           []   \n",
      "2181  6 days ago · If so, the EU's green transition ...    10           []   \n",
      "2182  4 days ago · There will be little space for tr...    10           []   \n",
      "\n",
      "     title_countries link_cities link_countries snippet_cities  \\\n",
      "0                 []          []             []             []   \n",
      "1                 []          []             []             []   \n",
      "2                 []          []             []             []   \n",
      "3                 []          []             []             []   \n",
      "5                 []          []             []             []   \n",
      "...              ...         ...            ...            ...   \n",
      "2174              []          []             []             []   \n",
      "2175              []          []             []        [March]   \n",
      "2176              []          []             []             []   \n",
      "2181              []          []             []             []   \n",
      "2182              []          []             []             []   \n",
      "\n",
      "     snippet_countries  \n",
      "0                   []  \n",
      "1                   []  \n",
      "2      [United States]  \n",
      "3                   []  \n",
      "5        [Philippines]  \n",
      "...                ...  \n",
      "2174                []  \n",
      "2175                []  \n",
      "2176                []  \n",
      "2181                []  \n",
      "2182                []  \n",
      "\n",
      "[1993 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from geotext import GeoText\n",
    "\n",
    "def extract_row_locations(row):\n",
    "    \"\"\"Process all text columns in a single row\"\"\"\n",
    "    result = {}\n",
    "    for col in ['title', 'link', 'snippet']:\n",
    "        places = GeoText(str(row[col]))\n",
    "        result[f'{col}_cities'] = places.cities\n",
    "        result[f'{col}_countries'] = places.countries\n",
    "    return pd.Series(result)\n",
    "\n",
    "# Apply row-wise (axis=1) to maintain original length\n",
    "location_df = df1.apply(extract_row_locations, axis=1)\n",
    "df2 = pd.concat([df1, location_df], axis=1)\n",
    "\n",
    "# Verify lengths match\n",
    "assert len(df2) == len(df1)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "461c7e13-a33d-4894-86b4-397571883579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 0, 'Philippines': 5, 'United States': 91, 'Turkey': 4, 'Uruguay': 1, 'France': 2, 'Argentina': 3, 'United Kingdom': 12, 'Netherlands': 2, 'Czechia': 3, 'Germany': 3, 'South Africa': 3, 'India': 1, 'Italy': 1, 'Kenya': 1, 'Canada': 3, 'Spain': 1, 'Chile': 1, 'Brazil': 1}\n"
     ]
    }
   ],
   "source": [
    "# Sort country names\n",
    "\n",
    "import numpy as np\n",
    "from geonamescache import GeonamesCache\n",
    "\n",
    "loc_cols = df2.columns[-6:].tolist()  # Last 6 columns\n",
    "\n",
    "for col in loc_cols:\n",
    "    # Convert to string (handles lists safely) while keeping original index/rows\n",
    "    df2[col] = df2[col].astype(str)\n",
    "\n",
    "# Initialize and get all cities data\n",
    "gc = GeonamesCache()\n",
    "cities = gc.get_cities()\n",
    "\n",
    "# Create city→country mapping (takes a few seconds to build)\n",
    "city_to_country = {}\n",
    "for city_id, city_data in cities.items():\n",
    "    city_name = city_data['name'].lower()\n",
    "    country_code = city_data['countrycode']\n",
    "    country_name = gc.get_countries()[country_code]['name']\n",
    "    city_to_country[city_name] = country_name\n",
    "\n",
    "# 2. Process DataFrame columns\n",
    "def extract_country(text):\n",
    "    \"\"\"Extract first valid city-country match from text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    cities_found = GeoText(str(text)).cities\n",
    "    for city in cities_found:\n",
    "        if city.lower() in city_to_country:\n",
    "            return city_to_country[city.lower()]\n",
    "    return None\n",
    "\n",
    "# 3. Apply to multiple columns in your DataFrame\n",
    "def add_country_column(df2, loc_cols, new_col_name='city_to_country'):\n",
    "    \"\"\"\n",
    "    Adds country column based on city detection in source columns\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        source_cols: List of columns to search for cities\n",
    "        new_col_name: Name for new country column\n",
    "    \"\"\"\n",
    "    # Combine text from all source columns\n",
    "    combined_text = df2[loc_cols].apply(\n",
    "        lambda row: ' '.join(row.dropna().astype(str)), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Create new country column\n",
    "    df2[new_col_name] = combined_text.apply(extract_country)\n",
    "    return df2\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df2 is your DataFrame and you want to process last 6 columns\n",
    "df_loc = add_country_column(df2, loc_cols)\n",
    "\n",
    "\n",
    "# Get unique values\n",
    "unique_loc = df2['city_to_country'].astype(str).replace('nan', np.nan).dropna().unique()\n",
    "\n",
    "# Count how many rows contain each substring\n",
    "loc_counts = {word: df2['city_to_country'].str.contains(word, case=False).sum() \n",
    "          for word in unique_loc}\n",
    "print(loc_counts)\n",
    "\n",
    "# print(ft.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "481e4eba-5774-4337-9581-8f23d761119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        query  rank  \\\n",
      "0            climate database     1   \n",
      "1            climate database     2   \n",
      "2            climate database     3   \n",
      "3            climate database     4   \n",
      "5            climate database     6   \n",
      "...                       ...   ...   \n",
      "2174  climate adaptation plan    90   \n",
      "2175  climate adaptation plan    92   \n",
      "2176  climate adaptation plan    93   \n",
      "2181  climate adaptation plan    72   \n",
      "2182  climate adaptation plan    80   \n",
      "\n",
      "                                                  title  \\\n",
      "0                             Climate Data Online (CDO)   \n",
      "1                    Search | Climate Data Online (CDO)   \n",
      "2                        Maps & Data | NOAA Climate.gov   \n",
      "3                    Climate - National Weather Service   \n",
      "5                 Climate Change Knowledge Portal: Home   \n",
      "...                                                 ...   \n",
      "2174  Adapting to the business future - Otago Daily ...   \n",
      "2175  NC Businesses Call for Commitment to Carbon Re...   \n",
      "2176  Aboitiz Foundation Champions Sustainability At...   \n",
      "2181  The Second Trump Administration and Europe's G...   \n",
      "2182  Op-Ed: Harrell's Growth Plan Shorts Housing an...   \n",
      "\n",
      "                                                   link  \\\n",
      "0                    https://www.ncei.noaa.gov/cdo-web/   \n",
      "1              https://www.ncdc.noaa.gov/cdo-web/search   \n",
      "2                     https://www.climate.gov/maps-data   \n",
      "3                   https://www.weather.gov/wrh/climate   \n",
      "5         https://climateknowledgeportal.worldbank.org/   \n",
      "...                                                 ...   \n",
      "2174  https://www.odt.co.nz/lifestyle/magazine/adapt...   \n",
      "2175  https://www.nrdc.org/press-releases/businesses...   \n",
      "2176  https://journal.com.ph/aboitiz-foundation-cham...   \n",
      "2181  https://www.globsec.org/what-we-do/commentarie...   \n",
      "2182  https://www.theurbanist.org/2025/03/29/harrell...   \n",
      "\n",
      "                                                snippet  page  \\\n",
      "0     Climate Data Online (CDO) provides free access...     1   \n",
      "1     Start searching here to find past weather and ...     1   \n",
      "2     This site provides data tables for comparing r...     1   \n",
      "3     For the latest climate forecasts see the Clima...     1   \n",
      "5     The Portal provides an online tool for access ...     1   \n",
      "...                                                 ...   ...   \n",
      "2174  6 days ago · Climate change adaptation for bus...     9   \n",
      "2175  3 days ago · Climate Adaptation · Fossil Fuels...     9   \n",
      "2176  17 hours ago · Themed “Advancing Private Secto...     9   \n",
      "2181  6 days ago · If so, the EU's green transition ...    10   \n",
      "2182  4 days ago · There will be little space for tr...    10   \n",
      "\n",
      "     detected_countries       countries  \n",
      "0                    []            None  \n",
      "1                    []            None  \n",
      "2       [United States]   United States  \n",
      "3                    []            None  \n",
      "5         [Philippines]     Philippines  \n",
      "...                 ...             ...  \n",
      "2174                 []            None  \n",
      "2175   [United Kingdom]  United Kingdom  \n",
      "2176                 []            None  \n",
      "2181                 []            None  \n",
      "2182                 []            None  \n",
      "\n",
      "[1993 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "ft = df2.drop(['link_countries', 'link_cities'], axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "from geotext import GeoText\n",
    "\n",
    "def extract_countries(text):\n",
    "    \"\"\"Extract unique country names from text using GeoText\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    text = str(text)\n",
    "    # Handle list-like strings if present\n",
    "    if text.startswith('[') and text.endswith(']'):\n",
    "        text = text[1:-1]  # Remove brackets\n",
    "    countries = GeoText(text).countries\n",
    "    return list(set(countries))  # Remove duplicates\n",
    "\n",
    "# Specify columns to scan (last 5 columns in this case)\n",
    "columns_to_scan = ['title_countries',\n",
    "              'title_cities',\n",
    "             'snippet_countries',\n",
    "             'snippet_cities',\n",
    "             'city_to_country']\n",
    "\n",
    "columns_to_scan = [col for col in columns_to_scan if col in ft.columns]\n",
    "\n",
    "# Create new column with aggregated country lists\n",
    "ft['detected_countries'] = (\n",
    "    ft[columns_to_scan]\n",
    "    .apply(lambda row: list(set(\n",
    "        country for col in row \n",
    "        for country in extract_countries(col)\n",
    "    )), axis=1)\n",
    ")\n",
    "\n",
    "ft['countries'] = ft['detected_countries'].apply(\n",
    "    lambda x: ', '.join(x) if x and len(x) > 0 else None\n",
    ")\n",
    "\n",
    "ft = ft.drop(['title_countries',\n",
    "              'title_cities',\n",
    "             'snippet_countries',\n",
    "             'snippet_cities',\n",
    "             'city_to_country'], axis=1)\n",
    "\n",
    "print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ed81111a-b35f-495d-bc9a-753a012bdba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query                                                  climate database\n",
      "rank                                                                  7\n",
      "title                                 Climate data for cities worldwide\n",
      "link                                       https://en.climate-data.org/\n",
      "snippet               In addition to weather and climate data for th...\n",
      "page                                                                  1\n",
      "detected_countries                          [Spain, Japan, Philippines]\n",
      "countries                                     Spain, Japan, Philippines\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def extract_and_format_countries(text):\n",
    "    \"\"\"\n",
    "    Extract countries using GeoText and format with commas\n",
    "    Returns None if no countries found\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        return None\n",
    "    \n",
    "    # Extract unique countries (case-insensitive)\n",
    "    countries = list(set(GeoText(str(text)).countries))\n",
    "    \n",
    "    if not countries:\n",
    "        return None\n",
    "    return ', '.join(countries) if len(countries) > 1 else countries[0]\n",
    "\n",
    "# Create new formatted column\n",
    "ft['countries'] = ft['countries'].apply(extract_and_format_countries)\n",
    "\n",
    "print(ft.loc[6])\n",
    "\n",
    "ft = ft.drop(['detected_countries'], axis=1)\n",
    "\n",
    "ft.to_csv('TRIALFORCURSOR.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
